# Automated Data Extraction System

A comprehensive system for extracting structured data from unstructured text using LLMs, agent orchestration, vector databases, and knowledge graphs.

## System Architecture

```
Unstructured Text Input
    ↓
LangGraph Agent Orchestration
(Extract → Validate → Store)
    ↓
Structured JSON Output
    ↓↓↓
Weaviate (Vector Database) | NebulaGraph (Knowledge Graph)
Semantic Search            | Entity Relationships
```

## Project Phases

### Phase 0: Environment Setup
- Project structure
- Dependencies installation
- Configuration management

### Phase 1: Entity Extraction
- LLM-based entity extraction
- Support for multiple LLM providers (OpenAI, Gemini, Ollama)
- Entity validation and confidence scoring

### Phase 2: Agentic Workflow (LangGraph)
- Multi-node agent orchestration
- Extract → Validate → Store pipeline
- Error handling and logging

### Phase 3: Vector Database (Weaviate)
- Document storage for semantic search
- Similarity-based retrieval
- Metadata management

### Phase 4: Knowledge Graph (NebulaGraph)
- Entity node creation
- Relationship edge creation
- Graph traversal and querying

### Phase 5: Integration & Demo
- End-to-end pipeline execution
- Semantic queries (Weaviate)
- Graph queries (NebulaGraph)

## Quick Start

### Prerequisites
- Python 3.8+
- Docker & Docker Compose
- API keys for LLM provider (OpenAI, Gemini, or local Ollama)

### Setup

1. Clone the repository and navigate to the project:
```bash
cd Data_extracter
```

2. Copy environment template and configure:
```bash
cp .env.example .env
# Edit .env with your API keys
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Start services:
```bash
docker-compose -f docker_configs/docker-compose.yml up -d
```

### Running the Pipeline

```bash
python phase_5_integration_demo/integrated_pipeline.py
```

## Configuration

Edit `.env` file to configure:
- LLM Provider (openai, gemini, ollama)
- Weaviate connection details
- NebulaGraph connection details

## Directory Structure

```
Data_extracter/
├── phase_0_setup/              # Environment configuration
├── phase_1_entity_extraction/  # LLM-based extraction
├── phase_2_agentic_workflow/   # LangGraph orchestration
├── phase_3_vector_database/    # Weaviate integration
├── phase_4_knowledge_graph/    # NebulaGraph integration
├── phase_5_integration_demo/   # Complete pipeline & demos
├── docker_configs/             # Docker Compose configuration
├── utils/                      # Utility functions
├── sample_data/                # Sample documents for testing
├── requirements.txt            # Python dependencies
└── .env.example               # Environment template
```

## Usage Examples

### Basic Entity Extraction
```python
from phase_1_entity_extraction.entity_extractor import extract_from_text

result = extract_from_text("John Smith from Acme Corp signed a deal on 2024-12-14")
for entity in result.entities:
    print(f"{entity.type}: {entity.value}")
```

### Agentic Workflow
```python
from phase_2_agentic_workflow.workflow import run_workflow

result = run_workflow("Your unstructured text here")
print(f"Status: {result['status']}")
print(f"Entities: {result['entities']}")
```

### Complete Pipeline
```python
from phase_5_integration_demo.integrated_pipeline import IntegratedPipeline

pipeline = IntegratedPipeline()
results = pipeline.run_complete_pipeline("Your text here")
```

## Technologies Used

- **Python 3.8+**: Core language
- **LangGraph**: Agent orchestration
- **LangChain**: LLM integration
- **Weaviate**: Vector database
- **NebulaGraph**: Knowledge graph
- **Docker**: Containerization

## LLM Provider Support

### OpenAI
```bash
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-...
```

### Google Gemini
```bash
LLM_PROVIDER=gemini
GEMINI_API_KEY=...
```

### Ollama (Local)
```bash
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
```

## Querying

### Semantic Search (Weaviate)
Find documents similar to a query using vector similarity:
```python
results = weaviate_client.semantic_search("contracts and agreements", limit=5)
```

### Graph Queries (NebulaGraph)
Find entity relationships:
```bash
FETCH PROP ON Person "person_john_smith";
FIND PATH FROM person_1 TO organization_1;
```

## Notes

- Ensure Docker services are running before execution
- Configure your LLM provider in .env
- The system creates graph spaces and schema automatically
- Vector embeddings are generated by Weaviate automatically

## Future Enhancements

- Multi-document processing
- Custom extraction rules
- Real-time streaming
- Advanced relationship inference
- Web UI dashboard
